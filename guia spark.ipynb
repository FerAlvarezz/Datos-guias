{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio N°1sdsdsds\n",
    "Se tiene un RDD con el registro de notas de los alumnos de la forma (padrón, materia, nota,\n",
    "fecha). Se pide resolver utilizando PySpark:\n",
    "\n",
    "- A. Cuántos alumnos aprobaron al menos 1 materia en los últimos 2 años.\n",
    "- B. Un RDD conteniendo el promedio de notas de cada alumno de la forma (padrón,\n",
    "promedio).\n",
    "- C. El nombre y apellido del alumno con mejor promedio. Para esto puede utilizarse un\n",
    "segundo RDD alumnos con registros (padron, nombre y apellido).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "notas = []\n",
    "padrones = []\n",
    "cant_alumnos = 50\n",
    "for i in range(cant_alumnos):\n",
    "    padron = random.randint(99900,100000)\n",
    "    while(padron in padrones): padron = random.randint(99900,100000)\n",
    "    padrones.append(padron)\n",
    "    materia = random.choice([\"AM3\",\"AM2\",\"TALLER\",\"LABORATORIO\",\"DATOS\"])\n",
    "    nota = random.randint(1,10)\n",
    "    fecha = \"{}-{}-{}\".format(random.choice(['2017','2018','2019']),\n",
    "                                        random.randint(1,12),\n",
    "                                        random.randint(1,28))\n",
    "    tupla = (padron,materia,nota,fecha)\n",
    "    notas.append(tupla)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "notasRDD = sc.parallelize(notas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#A\n",
    "notasRDD.filter(lambda x: x[3] >= '2018-01-01' and x[3]<= '2019-12-31' and x[2]>=4)\\\n",
    "        .count()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#B\n",
    "promediosRDD = notasRDD.map(lambda x: (x[0], (x[2],1)))\\\n",
    "                       .reduceByKey(lambda x,y: (x[0]+y[0], x[1]+y[1]))\\\n",
    "                       .map(lambda x: (x[0], x[1][0]/x[1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "alumnos = []\n",
    "for i in range(cant_alumnos):\n",
    "    padron = padrones[i]\n",
    "    nombre = random.choice([\"Gustavo\",\"Nicolas\",\"Mariana\",\"Florencia\",\"Ayelen\",\"Pedro\",\"Gonzalo\"])\n",
    "    apellido = random.choice([\"Alvarez\",\"Fernandez\",\"Gonzalez\",\"Ramirez\",\"Rodriguez\"])\n",
    "    alumno = (padron, nombre, apellido)\n",
    "    alumnos.append(alumno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "alumnosRDD = sc.parallelize(alumnos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Mariana Alvarez', 10.0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#C\n",
    "alumnosRDD.map(lambda x: (x[0], (x[1] + ' ' + x[2])))\\\n",
    "          .join(promediosRDD)\\\n",
    "          .map(lambda x: (x[1][0], x[1][1]))\\\n",
    "          .reduce(lambda x,y: x if x[1]>=y[1] else y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio N°2\n",
    "Se tiene un RDD registros de ventas de producto con la forma (fecha de venta, código de\n",
    "producto, precio de venta) y en otro RDD detalle de los productos con (código de producto,\n",
    "descripción del producto, categoría). Se pide resolver utilizando PySpark:\n",
    "- A. Cuál es el producto más vendido.\n",
    "- B. Cuál es la categoría de productos más vendida.\n",
    "- C. Cuál es el top5 de productos más vendidos generando un RDD con (código de\n",
    "producto, descripción, cantidad de ventas)\n",
    "- D. Cuál es el producto que registró mayor aumento de precio en el último año, tomando\n",
    "para este análisis solo los productos que cuenten con al menos 50 ventas en el último\n",
    "año.\n",
    "- E. Idem anterior, pero calculando la categoría de productos que registró mayor variación\n",
    "de precios en el último año."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ventas = []\n",
    "productos = []\n",
    "\n",
    "for i in range(10000):\n",
    "    fecha_de_venta = \"{}-{}-{}\".format(random.choice([\"2018\",\"2019\"])\n",
    "                                                     ,random.choice([\"01\",\"02\",\"03\",\"04\",\"05\",\"06\",\"07\",\"08\",\"09\",\"10\",\"11\",\"12\"])\n",
    "                                                     ,random.randint(1,28))\n",
    "    codigo_de_producto = random.randint(0,10)\n",
    "    precio_de_venta = round(random.uniform(100,5000),2)\n",
    "    venta = (fecha_de_venta, codigo_de_producto, precio_de_venta)\n",
    "    ventas.append(venta)\n",
    "for i in range(0,10):\n",
    "    codigo_de_producto = i\n",
    "    descripcion = \"descripcion\" + ' ' + str(i)\n",
    "    categoria = random.choice([\"Limpieza\",\"Producto de cocina\", \"Vestimenta\", \"Juguete\"])\n",
    "    producto = (codigo_de_producto, descripcion, categoria)\n",
    "    productos.append(producto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ventasRDD = sc.parallelize(ventas)\n",
    "productosRDD = sc.parallelize(productos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 944)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#A - (Codigo_producto, cantidad_vendida)\n",
    "ventasRDD.map(lambda x: (x[1],1))\\\n",
    "         .reduceByKey(lambda x,y: x+y)\\\n",
    "         .reduce(lambda x,y: x if x[1]>y[1] else y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Limpieza', 944)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#B\n",
    "cant = ventasRDD.map(lambda x: (x[1],1))\\\n",
    "                .reduceByKey(lambda x,y: x+y)\n",
    "#cant es un RDD con las cantidades de venta de cada prod [(id_producto, cant)]\n",
    "productosRDD.map(lambda x: (x[0], x[2]))\\\n",
    "            .join(cant)\\\n",
    "            .map(lambda x: (x[1][0], x[1][1]))\\\n",
    "            .reduce(lambda x,y: x if x[1] >= y[1] else y ) \n",
    "#Me devuelve la tupla (categoria,cant), puedo hacer [0] y obtener la categoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#C\n",
    "productosRDD_map = productosRDD.map(lambda x: (x[0], x[1]))\n",
    "top5RDD = sc.parallelize(cant.top(5,key = lambda x: x[1]))\\\n",
    "            .join(productosRDD_map)\\\n",
    "            .map(lambda x: (x[0],x[1][1],x[1][0]))\n",
    "top5RDD.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5, 'descripcion 5', 944),\n",
       " (2, 'descripcion 2', 936),\n",
       " (9, 'descripcion 9', 922),\n",
       " (3, 'descripcion 3', 914)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top5RDD.takeOrdered(5,key = lambda x: -x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#D\n",
    "#Ult año me va a servir para poder filtrar los que tengan mas de 50 ventas en el ultimo año. \n",
    "ult_año = ventasRDD.filter(lambda x: x[0] >= \"2018-01\" and x[0] <= \"2019-01\")\\\n",
    "                   .map(lambda x: (x[1],1))\\\n",
    "                   .reduceByKey(lambda x,y: x+y)\\\n",
    "                   .filter(lambda x: x[1] >= 50)\n",
    "\n",
    "ventas_sep = ventasRDD.map(lambda x: (x[1], (x[0],x[2])))\\\n",
    "                      .join(ult_año)\\\n",
    "                      .map(lambda x: (x[1][0][0], x[0], x[1][0][1]))\\\n",
    "                      .map(lambda x: (0,(x[1],x[2])) if (x[0] >= \"2018-01\" and x[0] <= \"2018-02\")\\\n",
    "                        else ((1,(x[1],x[2])) if (x[0]>=\"2018-12\" and x[0]<= \"2019-01\") else None))\\\n",
    "                      .filter(lambda x: x!= None)\\\n",
    "                      .map(lambda x: ((x[0],x[1][0]), x[1][1]))\\\n",
    "                      .reduceByKey(lambda x,y: x if x>y else y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def porcent(x):\n",
    "    porc = (x[1][1]*100/x[1][0]) - 100\n",
    "    return round(porc,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 5.17)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ventas_primer_mes = ventas_sep.filter(lambda x: x[0][0] == 0).map(lambda x: (x[0][1], x[1]))\n",
    "ventas_segund_mes = ventas_sep.filter(lambda x: x[0][0] == 1).map(lambda x: (x[0][1], x[1]))\n",
    "ventas_primer_mes.join(ventas_segund_mes)\\\n",
    "                               .map(lambda x: (x[0], porcent(x)))\\\n",
    "                               .top(1,key = lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Producto de cocina', 27.22)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#E\n",
    "productosRDD_map = productosRDD.map(lambda x: (x[0], x[2]))\n",
    "\n",
    "ult_año = ventasRDD.filter(lambda x: x[0] >= \"2018-01\" and x[0] <= \"2019-01\")\\\n",
    "                   .map(lambda x: (0,(x[1],x[2])) if (x[0] >= \"2018-01\" and x[0] <= \"2018-02\")\\\n",
    "                        else ((1,(x[1],x[2])) if (x[0]>=\"2018-12\" and x[0]<= \"2019-01\") else None))\\\n",
    "                   .filter(lambda x: x!= None)\\\n",
    "                   .map(lambda x: (x[1][0], (x[1][1], x[0] )))\\\n",
    "                   .join(productosRDD_map)\\\n",
    "                   .map(lambda x: ( (x[1][1],x[1][0][1]),x[1][0][0]))\\\n",
    "                   .reduceByKey(lambda x,y: x+y)\n",
    "\n",
    "ventas_primer_mes = ult_año.filter(lambda x: x[0][1] == 0).map(lambda x: (x[0][0], x[1]))\n",
    "ventas_segund_mes = ult_año.filter(lambda x: x[0][1] == 1).map(lambda x: (x[0][0], x[1]))\n",
    "ventas_primer_mes.join(ventas_segund_mes)\\\n",
    "                 .map(lambda x: (x[0], porcent(x)))\\\n",
    "                 .top(1,key = lambda x: x[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio N°3\n",
    "\n",
    "Se tiene un RDD con información de vuelos programados con la forma (número de vuelo, código de aerolínea, código de aeropuerto de salida, código de aeropuerto de llegada, fecha de salida AAAAMMDD, hora de salida HH:MM, fecha de llegada AAAAMMDD, hora de llegada HH:MM). \n",
    "\n",
    "A su vez, se cuenta con el registro actualizado del estado de los vuelos que fueron ocurriendo, con la forma (número de vuelo, aerolínea, fecha de salida AAAAMMDD, hora de salida HH:MM, fecha de llegada AAAAMMDD, hora de llegada HH:MM, estado).\n",
    "\n",
    "En base al estado, podría contar con algún dato en blanco, por ejemplo si el vuelo fue cancelado no tendrá información de fechas y horas, si el vuelo se encuentra aún en curso, no contendrá información de la llegada. Se pide resolver utilizando PySpark:\n",
    "\n",
    "- A. Cuál es el aeropuerto con mayor tránsito.\n",
    "- B. Cuál es la aerolínea con mayor cantidad de vuelos.\n",
    "- C. Cuál es la aerolínea con mayor cantidad de cancelaciones.\n",
    "- D. Cuál es el vuelo (numero de vuelo + fecha) con mayor retraso en el horario de salida.\n",
    "- E. Cuál es el vuelo (numero de vuelo + fecha) con mayor retraso en el horario de llegada.\n",
    "- F. Cuál es la aerolínea más puntual.\n",
    "- G. Cuál es el aeropuerto que registra mayor desviación con - respecto a los horarios coordinados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vuelos = [(1,1,'MDQ','EZ', '20191214', '15:30', '20191214', '17:30')]\n",
    "estados = [(1, 'Aerolineas', '20191214', '15:45', '20191214', '18:00', 3)]\n",
    "vuelosRDD = sc.parallelize(vuelos)\n",
    "estadosRDD = sc.parallelize(estados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('EZ', 1)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#A\n",
    "vuelosRDD.map(lambda x: ((x[0],x[3]), 1 ))\\\n",
    "         .reduceByKey(lambda x,y: x+y)\\\n",
    "         .map(lambda x: (x[0][1],x[1]))\\\n",
    "         .top(1, key= lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#B\n",
    "vuelosRDD.map(lambda x: ((x[0],x[1]),1))\\\n",
    "         .reduceByKey(lambda x,y: x+y)\\\n",
    "         .map(lambda x: (x[0][1],x[1]))\\\n",
    "         .top(1, key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#C\n",
    "estadosRDD.filter(lambda x: x[6] == \"Cancelado\")\\\n",
    "          .map(lambda x: (x[1],1))\\\n",
    "          .reduceByKey(lambda x,y: x+y)\\\n",
    "          .top(1,key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, datetime.time(15, 30))]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#D\n",
    "horario_ideal = vuelosRDD.map(lambda x: ((x[0],x[4]), datetime.strptime(x[5], \"%H:%M\").time()))\n",
    "horario_real = estadosRDD.map(lambda x: ((x[0],x[2]), datetime.strptime(x[3], \"%H:%M\").time()))\n",
    "horario_ideal.join(horario_real)\\\n",
    "             .map(lambda x: ([0][0], x[1][0] - x[1][1])).collect()\n",
    "             .top(1, key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((1, '20191214'), datetime.time(15, 30))]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#E\n",
    "horario_ideal = vuelosRDD.map(lambda x: ((x[0],x[6]), datetime.strptime(x[7], \"%H:%M\").time()))\n",
    "horario_real = estadosRDD.map(lambda x: ((x[0],x[4]), datetime.strptime(x[5], \"%H:%M\").time()))\n",
    "horario_ideal.join(horario_real)\\\n",
    "             .map(lambda x: ([0][0], x[1][0] - x[1][1])).collect()\n",
    "             .top(1, key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#F\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio N°4\n",
    "Se tiene un RDD con las coordenadas de rectángulos de la forma (x1,x2,y1,y2). Se pide\n",
    "programar en PySpark un programa que encuentre el rectángulo de superficie mínima que\n",
    "contiene al punto (w,z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "rectangulos = []\n",
    "\n",
    "for i in range(100):\n",
    "    x1 = random.randint(1,50)\n",
    "    x2 = random.randint(2,51)\n",
    "    if x2 <= x1: x2 = random.randint(2,51)\n",
    "    y1 = random.randint(1,50)\n",
    "    y2 = random.randint(2,51)\n",
    "    if y2 <= y1: y2 = random.randint(2,51)\n",
    "    rectangulos.append( (x1,x2,y1,y2) )\n",
    "    \n",
    "rectangulosRDD = sc.parallelize(rectangulos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 10\n",
    "z = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((3, 41, 5, 16), 8)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rectangulosRDD.filter(lambda x: w >= x[0] and w <= x[1] and z >= x[2] and z <= x[3])\\\n",
    "              .map(lambda x: ((x[0],x[1],x[2],x[3]),abs(x[1] - x[0] * (x[3] - x[2]))))\\\n",
    "              .top(1, key = lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio N°5\n",
    "Se tiene un RDD con libros en donde cada registro es un texto. Se pide obtener todos los\n",
    "anagramas de mas de 7 letras que puedan encontrarse. El formato de salida debe ser una lista\n",
    "de listas en donde cada lista tiene un conjunto de palabras que son anagramas. Ejemplo:\n",
    "[[discounter,introduces,reductions],[percussion,supersonic]...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_key(word):\n",
    "    rep = []\n",
    "    word = ','.join(word).split(',')\n",
    "    word = sorted(word)\n",
    "    for i,letter in enumerate (word):\n",
    "        if(letter == word[i-1]): continue\n",
    "        rep.append(word.count(letter))\n",
    "    return (word, rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separador(text):\n",
    "    reg = []\n",
    "    words = text.split(' ')\n",
    "    for word in words: \n",
    "        if(len(word) < 7): continue\n",
    "        key = generate_key(word.lower())\n",
    "        reg.append((key,word))\n",
    "    return reg    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuentos = [\"Aaadhlmo Aaadhlom Aaadhmlo Aaadhmol Aaadholm Aaadhoml Aaadlhmo Aaadlhom Aaadlmho Aaadlmoh Aaadlohm Aaadlomh Aaadmhlo Aaadmhol almohada\",\"Estaban introduces acaso a la puerta discounter dos mujeres mozas,percussion destas que supersonic llaman del partido, las cuales iban a Sevilla con unos arrieros que en la venta aquella noche acertaron a hacer jornada; y, como a nuestro aventurero todo cuanto pensaba, veía o imaginaba le parecía ser hecho y pasar al modo de lo que había leído, luego que vio la venta, se le representó que era un castillo con sus cuatro torres y chapiteles de luciente plata, sin faltarle su puente levadiza y honda cava, con\", \"lalalala\"]\n",
    "librosRDD = sc.parallelize(cuentos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "llaves = librosRDD.map(lambda x: \" \".join(re.findall(\"[a-zA-Z]+\", x)))\\\n",
    "         .map(lambda x: separador(x)).collect()\n",
    "palabras = []\n",
    "for i in llaves:\n",
    "    for llave in i:\n",
    "        palabras.append(llave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mujeres',\n",
       " 'partido',\n",
       " 'aquella',\n",
       " 'jornada',\n",
       " 'nuestro',\n",
       " 'aventurero',\n",
       " 'pensaba',\n",
       " 'castillo',\n",
       " 'luciente',\n",
       " 'levadiza',\n",
       " 'lalalala',\n",
       " 'Aaadhlmo,Aaadhlom,Aaadhmlo,Aaadhmol,Aaadholm,Aaadhoml,Aaadlhmo,Aaadlhom,Aaadlmho,Aaadlmoh,Aaadlohm,Aaadlomh,Aaadmhlo,Aaadmhol,almohada',\n",
       " 'Estaban',\n",
       " 'introduces,discounter',\n",
       " 'percussion,supersonic',\n",
       " 'Sevilla',\n",
       " 'arrieros',\n",
       " 'acertaron',\n",
       " 'imaginaba',\n",
       " 'represent',\n",
       " 'chapiteles',\n",
       " 'faltarle']"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "palabrasRDD = sc.parallelize(palabras)\n",
    "palabrasRDD.map(lambda x: ((tuple(x[0][0]), tuple(x[0][1])), x[1]))\\\n",
    "           .reduceByKey(lambda x,y: x+ ',' +y)\\\n",
    "           .map(lambda x: x[1]).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio N°6\n",
    "UBER almacena en un cluster todos los datos sobre el movimiento y viajes de todos sus\n",
    "vehículos. Existe un proceso que nos devuelve un RDD llamado trip_summary con los\n",
    "siguientes campos: (driver_id, car_id, trip_id, customer_id, date (YYYYMMDD),\n",
    "distance_traveled), Programar usando Py Spark un programa que nos indique cual fue el\n",
    "conductor con mayor promedio de distancia recorrida por viaje para Abril de 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = []\n",
    "n = 1000\n",
    "for i in range(n):\n",
    "    driver_id = random.randint(1,25)\n",
    "    car_id = driver_id\n",
    "    trip_id = i\n",
    "    customer_id = random.randint(1,n)\n",
    "    date = \"{}{}{}\".format(random.randint(2015,2017)\n",
    "                           ,random.choice([\"01\",\"02\",\"03\",\"04\",\"05\",\"06\",\"07\",\"08\",\"09\",\"10\",\"11\",\"12\"])\n",
    "                           ,random.choice([\"01\",\"02\",\"03\",\"04\",\"05\",\"06\",\"07\",\"08\",\"09\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"27\",\"28\"]))\n",
    "    distance_traveled = random.randint(10,100)\n",
    "    datos.append((driver_id, car_id, trip_id, customer_id, date, distance_traveled))\n",
    "datosRDD = sc.parallelize(datos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(6, 100.0)]"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datosRDD.filter(lambda x: x[4] >= '20160401' and x[4] <= '20160428')\\\n",
    "        .map(lambda x: (x[0],(x[5],1)))\\\n",
    "        .reduceByKey(lambda x,y: (x[0] + y[0], x[1] + y[1]))\\\n",
    "        .map(lambda x: (x[0],x[1][0]/x[1][1]))\\\n",
    "        .top(1, key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio N°7\n",
    "Una red social almacena el contenido de los chats entre sus usuarios en un RDD que tiene\n",
    "registros con el siguiente formato: (chat_id, user_id, nickname, text). Queremos saber cuál es el\n",
    "usuario (user_id) que mas preguntas hace en sus chats, contabilizamos una pregunta por cada\n",
    "caracter “?” que aparezca en el campo text. Programar en Spark un programa que identifique al\n",
    "usuario preguntón."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatsRDD = sc.parallelize([(1,2,'bokita_el_mejor', '??????????????????????'), (2,2,'bokita_el_mejor', '??????'), (3,1,'ndeah','????????????????????????????????????????????????????????????????')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 64)]"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatsRDD.map(lambda x: (x[1], x[3].count('?')) )\\\n",
    "        .reduceByKey(lambda x,y: x+y)\\\n",
    "        .top(1, key= lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio N°8\n",
    "Contamos con un cluster que tiene 4 computadoras. Queremos aprovechar el paralelismo\n",
    "del cluster para calcular los números primos entre 2 y 20.000.000. Para esto usaremos el\n",
    "conocido algoritmo de la criba de Eratóstenes. Por ejemplo si empezamos con una lista de tipo\n",
    "(2,3,4,5,6,7,8...) en un primer paso eliminamos todos los que son mayores a 2 y divisibles por 2\n",
    "y nos queda (2,3,5,7,9,11,13...) luego eliminamos todos los mayores a 3 divisibles por 3 y nos\n",
    "queda (2,3,5,7,11,13....etc) luego todos los divisibles por 5 y así sucesivamente. El resultado\n",
    "final es una lista de números que son primos. Programar este programa usando PySpark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
